{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10033.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10004.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10010.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10009.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10005.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10002.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10003.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10019.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10001.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10006.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10008.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10089.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Input/a10007.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10033.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10004.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10010.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10009.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10005.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10002.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10003.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10019.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10001.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10006.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10008.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10089.png\n",
      "/home/mianzhi/Desktop/Carnava/dataset/Test/Target/a10007.png\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from inference import predict\n",
    "from transformations import normalize_01, re_normalize\n",
    "from unet import UNet\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'dataset' / 'Test'\n",
    "# root = pathlib.Path.cwd() / 'Test' \n",
    "# root = pathlib.Path.cwd() / 'TheYoung'\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "images_names = get_filenames_of_path(root / 'Input')\n",
    "targets_names = get_filenames_of_path(root / 'Target')\n",
    "\n",
    "# read images and store them in memory\n",
    "images = [imread(img_name) for img_name in images_names]\n",
    "\n",
    "for img_name in images_names:\n",
    "    print(img_name)\n",
    "\n",
    "targets = [imread(tar_name) for tar_name in targets_names]\n",
    "\n",
    "\n",
    "for img_name in targets_names:\n",
    "    print(img_name)\n",
    "\n",
    "# Resize images and targets\n",
    "images_res = [resize(img, (128, 128, 3)) for img in images]\n",
    "resize_kwargs = {'order': 0, 'anti_aliasing': False, 'preserve_range': True}\n",
    "targets_res = [resize(tar, (128, 128), **resize_kwargs) for tar in targets]\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "# model\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=2,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "\n",
    "model_name = 'lr0001epoch200.pt'\n",
    "model_weights = torch.load(model_name)\n",
    "\n",
    "model.load_state_dict(model_weights)\n",
    "\n",
    "# preprocess function\n",
    "def preprocess(img: np.ndarray):\n",
    "    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]\n",
    "    img = normalize_01(img)  # linear scaling to range [0-1]\n",
    "    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]\n",
    "    img = img.astype(np.float32)  # typecasting to float32\n",
    "    return img\n",
    "\n",
    "\n",
    "# postprocess function\n",
    "def postprocess(img: torch.tensor):\n",
    "    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel\n",
    "    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray\n",
    "    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]\n",
    "    img = re_normalize(img)  # scale it to the range [0-255]\n",
    "    return img\n",
    "\n",
    "# predict the segmentation maps \n",
    "output = [predict(img, model, preprocess, postprocess, device) for img in images_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "idx = 3\n",
    "img_nap = viewer.add_image(images_res[idx], name='Input')\n",
    "tar_nap = viewer.add_labels(targets_res[idx], name='Target')\n",
    "out_nap = viewer.add_labels(output[idx], name='Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2eb45a6a748982d8aec0be0926159fcd2f36db3ecea14f31531b7b105c0f8b9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('forpytorch11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
